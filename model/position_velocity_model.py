#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Position-Velocity-MMU/CMU Model for Smart Home Activity Recognition
====================================================================

í•µì‹¬ êµ¬ì¡°:
1. PositionHead: í•™ìŠµ ê°€ëŠ¥í•œ ì„¼ì„œ 2D ìœ„ì¹˜
2. VelocityHead: ìœ„ì¹˜ ì°¨ë¶„ìœ¼ë¡œ ì†ë„/ë°©í–¥/ì´ë™ íŠ¹ì§• ì¶”ì¶œ
3. MMU (Movement Memory Unit): ì´ë™ íŒ¨í„´ ê¸°ì–µ
4. CMU (Context Memory Unit): ë§¥ë½/ì˜ì—­ ê¸°ì–µ
5. GateAndTrigger: ì´ë™/ë§¥ë½ ë™ì  ìœµí•©
6. TemporalEncoder: TCN â†’ BiGRU â†’ Attention
7. Classifier: ìµœì¢… í™œë™ ë¶„ë¥˜

ì…ë ¥:
- X_base: [B, T, F_base] (rich features: frame+ema+vel+emb)
- sensor_ids: [B, T] (ê° ì‹œì ì˜ ëŒ€í‘œ ì„¼ì„œ ID)
- timestamps: [B, T] (ì„ íƒì , ì´ˆ ë‹¨ìœ„ float)

ì¶œë ¥:
- logits: [B, n_classes]
- aux: dict (pos, vel, move_flag, gate, trigger, attn ë“±)
"""

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Tuple, Dict


# ==================== Utility Modules ====================

class TCNBlock(nn.Module):
    """Temporal Convolutional Network with causal padding"""
    
    def __init__(self, in_ch, out_ch, k=3, dil=1, pdrop=0.1):
        super().__init__()
        pad = (k - 1) * dil
        self.net = nn.Sequential(
            nn.Conv1d(in_ch, out_ch, k, padding=pad, dilation=dil),
            nn.ReLU(),
            nn.Dropout(pdrop),
            nn.Conv1d(out_ch, out_ch, k, padding=pad, dilation=dil),
            nn.ReLU(),
            nn.Dropout(pdrop),
        )
        self.skip = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()

    def forward(self, x):
        """
        Args:
            x: [B, C, T]
        Returns:
            [B, C, T]
        """
        y = self.net(x)
        # Causal trim to match input length
        trim = y.size(-1) - x.size(-1)
        if trim > 0:
            y = y[..., :-trim]
        return y + self.skip(x)


class AdditiveAttention(nn.Module):
    """Additive (Bahdanau-style) attention mechanism"""
    
    def __init__(self, hid):
        super().__init__()
        self.scorer = nn.Linear(hid, 1, bias=False)

    def forward(self, H):
        """
        Args:
            H: [B, T, H]
        Returns:
            ctx: [B, H] - context vector
            w: [B, T] - attention weights
        """
        score = self.scorer(H)               # [B, T, 1]
        w = F.softmax(score, dim=1)          # [B, T, 1]
        ctx = (H * w).sum(dim=1)             # [B, H]
        return ctx, w.squeeze(-1)


# ==================== Core Components ====================

class PositionHead(nn.Module):
    """
    í•™ìŠµ ê°€ëŠ¥í•œ ì„¼ì„œ 2D ìœ„ì¹˜
    
    ì„ í–‰ ì—°êµ¬: ëŒ€ë¶€ë¶„ ê³ ì • ìœ„ì¹˜ ì‚¬ìš© â†’ ìš°ë¦¬ëŠ” end-to-end í•™ìŠµ ğŸ†•
    """
    
    def __init__(self, vocab_size: int, init_scale: float = 0.1):
        """
        Args:
            vocab_size: ì„¼ì„œ ê°œìˆ˜
            init_scale: ì´ˆê¸° ìœ„ì¹˜ ë¶„ì‚°
        """
        super().__init__()
        # í•™ìŠµ ê°€ëŠ¥í•œ 2D ì¢Œí‘œ (N_sensor, 2) - uniform init for stability
        positions = torch.empty(vocab_size, 2)
        nn.init.uniform_(positions, -init_scale, init_scale)
        self.positions = nn.Parameter(positions)

    def forward(self, sensor_ids: torch.Tensor) -> torch.Tensor:
        """
        Args:
            sensor_ids: [B, T] - ê° ì‹œì ì˜ ì„¼ì„œ ID
        Returns:
            [B, T, 2] - 2D ìœ„ì¹˜ ì‹œí€€ìŠ¤
        """
        return self.positions[sensor_ids]  # [B, T, 2]


class VelocityHead(nn.Module):
    """
    ì†ë„/ë°©í–¥ íŠ¹ì§• ì¶”ì¶œ + EMA í‰í™œí™” + ë°©í–¥ ì„ë² ë”©
    
    ì¶œë ¥:
    - Î”P (ìœ„ì¹˜ ì°¨ë¶„)
    - Î”t (ì‹œê°„ ì°¨ë¶„)
    - speed (EMA í‰í™œ)
    - direction (EMA í‰í™œ)
    - move_flag (ì´ë™/ì •ì§€ ì´ì§„ í”Œë˜ê·¸)
    - direction embedding (8ë°©ìœ„ ì„ë² ë”©)
    """
    
    def __init__(
        self,
        d_model: int = 32,
        dir_emb_dim: int = 8,
        ema_alpha: float = 0.3,
        move_thresh: float = 0.1,
        num_dir_bins: int = 8
    ):
        """
        Args:
            d_model: ì¶œë ¥ ì„ë² ë”© ì°¨ì›
            dir_emb_dim: ë°©í–¥ ì„ë² ë”© ì°¨ì›
            ema_alpha: EMA ê°ì‡ ìœ¨
            move_thresh: ì´ë™ íŒì • ì„ê³„ê°’
            num_dir_bins: ë°©í–¥ êµ¬ê°„ ê°œìˆ˜ (8 = 8ë°©ìœ„)
        """
        super().__init__()
        self.ema_alpha = ema_alpha
        self.move_thresh = move_thresh
        self.num_dir_bins = num_dir_bins

        # 6D ì…ë ¥ ì¸ì½”ë”: [Î”x, Î”y, Î”t, speed, direction, move_flag]
        self.encoder = nn.Sequential(
            nn.Linear(6, d_model),
            nn.LayerNorm(d_model),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model)
        )
        
        # ë°©í–¥ ì„ë² ë”© (0=stationary, 1-8=8ë°©ìœ„)
        self.dir_emb = nn.Embedding(num_dir_bins + 1, dir_emb_dim)
        
        # ìµœì¢… projection
        self.out_proj = nn.Linear(d_model + dir_emb_dim, d_model)
        
        # ë³´ì¡° ê³¼ì œ: ì´ë™ ë¶„ë¥˜ (moving vs stationary)
        self.mov_cls = nn.Linear(d_model, 2)

    @staticmethod
    def _ema(x, alpha):
        """
        Exponential Moving Average (gradient-friendly cumsum version)
        
        Args:
            x: [B, T, C]
            alpha: ê°ì‡ ìœ¨
        Returns:
            [B, T, C] - smoothed
        """
        # Use convolution for EMA (fully differentiable)
        B, T, C = x.shape
        
        # Simple exponential weighting
        # y_t = alpha * x_t + (1-alpha) * y_{t-1}
        # This is equivalent to convolution with exponential kernel
        y = torch.zeros_like(x)
        y[:, 0] = x[:, 0]
        
        for t in range(1, T):
            y[:, t] = alpha * x[:, t] + (1 - alpha) * y[:, t - 1]
        
        return y

    def forward(
        self,
        sensor_pos: torch.Tensor,
        timestamps: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor, Dict[str, torch.Tensor]]:
        """
        Args:
            sensor_pos: [B, T, 2] - ì„¼ì„œ 2D ìœ„ì¹˜ ì‹œí€€ìŠ¤
            timestamps: [B, T] - íƒ€ì„ìŠ¤íƒ¬í”„ (ì˜µì…˜, ì—†ìœ¼ë©´ Î”t=1)
        
        Returns:
            vel: [B, T, d_model] - ì†ë„ ì„ë² ë”©
            move_flag: [B, T] - ì´ë™ ì—¬ë¶€ (0=ì •ì§€, 1=ì´ë™)
            aux: dict - ì¤‘ê°„ ê³„ì‚° ê²°ê³¼ë“¤
        """
        B, T, _ = sensor_pos.shape
        device = sensor_pos.device

        # 1) ìœ„ì¹˜ ì°¨ë¶„ Î”P
        dP = torch.zeros_like(sensor_pos)
        dP[:, 1:] = sensor_pos[:, 1:] - sensor_pos[:, :-1]  # [B, T, 2]

        # 2) ì‹œê°„ ì°¨ë¶„ Î”t
        if timestamps is not None:
            dt = torch.ones(B, T, 1, device=device)  # initialize with 1s
            dt_raw = timestamps[:, 1:] - timestamps[:, :-1]
            # CRITICAL: Replace dt=0 with 1.0 to prevent division by zero
            dt_raw = torch.where(dt_raw > 0.01, dt_raw, torch.ones_like(dt_raw))
            dt[:, 1:, 0] = torch.clamp(dt_raw, 0.1, 1000.0)  # min 0.1ì´ˆ, max 1000ì´ˆ
        else:
            dt = torch.ones(B, T, 1, device=device)

        # 3) ì†ë„ (ê±°ë¦¬ / ì‹œê°„) - clamp to prevent explosion
        distance = torch.norm(dP, dim=-1, keepdim=True) + 1e-8  # [B, T, 1]
        # Normalize dt to reasonable scale before division
        dt_safe = torch.clamp(dt, 0.1, 1000.0) / 10.0  # [0.01, 100]
        speed = distance / (dt_safe + 1e-6)  # [B, T, 1]
        speed = torch.clamp(speed, 0, 10.0)  # clamp speed to reasonable range

        # 4) ë°©í–¥ (atan2)
        # CRITICAL: Add epsilon to prevent gradient explosion when dP is near zero
        dP_safe = dP + 1e-8
        direction = torch.atan2(dP_safe[..., 1], dP_safe[..., 0]).unsqueeze(-1)  # [B, T, 1], [-Ï€, Ï€]
        direction_norm = torch.clamp(direction / math.pi, -1.0, 1.0)  # normalize to [-1, 1]

        # 5) EMA í‰í™œí™”
        speed_s = self._ema(speed, self.ema_alpha)
        dir_s = self._ema(direction_norm, self.ema_alpha)

        # 6) ì´ë™ í”Œë˜ê·¸
        move_flag = (speed_s.squeeze(-1) > self.move_thresh).float()  # [B, T]

        # 7) 6D íŠ¹ì§• êµ¬ì„±: [Î”x, Î”y, Î”t, speed, direction, move_flag]
        feats = torch.cat([
            dP,                        # [B, T, 2]
            dt,                        # [B, T, 1]
            speed_s,                   # [B, T, 1]
            dir_s,                     # [B, T, 1]
            move_flag.unsqueeze(-1)    # [B, T, 1]
        ], dim=-1)  # [B, T, 6]

        # 8) ê¸°ë³¸ ì„ë² ë”©
        base = self.encoder(feats)  # [B, T, d_model]

        # 9) ë°©í–¥ ì„ë² ë”© (8ë°©ìœ„)
        ang = (dir_s.squeeze(-1) + 1) * math.pi  # [0, 2Ï€]
        bins = (ang / (2 * math.pi) * self.num_dir_bins).long().clamp(
            0, self.num_dir_bins - 1
        )
        bins = bins * move_flag.long()  # stationaryë©´ bin=0
        dir_emb = self.dir_emb(bins)    # [B, T, dir_emb_dim]

        # 10) ìµœì¢… ì†ë„ ì„ë² ë”©
        vel = self.out_proj(torch.cat([base, dir_emb], dim=-1))  # [B, T, d_model]

        # 11) ë³´ì¡° ê³¼ì œ: ì´ë™ ë¶„ë¥˜ logits
        mov_logits = self.mov_cls(vel)  # [B, T, 2]

        # 12) Auxiliary outputs
        aux = dict(
            dP=dP,
            dt=dt,
            speed=speed_s,
            direction=dir_s,
            move_flag=move_flag,
            mov_logits=mov_logits
        )
        
        return vel, move_flag, aux


class MMU(nn.Module):
    """
    Movement Memory Unit (ì´ë™ ë©”ëª¨ë¦¬)
    
    ì´ë™ íŒ¨í„´ì„ ëˆ„ì  í•™ìŠµ:
    - ì†ë„ ë²¡í„° ì‹œí€€ìŠ¤
    - ëˆ„ì  ì´ë™/ì •ì§€ ì¹´ìš´í„°
    - GRUë¡œ temporal dependencies ëª¨ë¸ë§
    
    ë…¸ë²¨í‹°: Movement-specific memory (ì„ í–‰ ì—°êµ¬ ê±°ì˜ ì—†ìŒ) ğŸ†•
    """
    
    def __init__(self, in_dim: int, hid: int = 128):
        """
        Args:
            in_dim: ì†ë„ ì„ë² ë”© ì°¨ì›
            hid: GRU hidden ì°¨ì›
        """
        super().__init__()
        # ì…ë ¥: vel + move_cnt + stay_cnt
        self.gru = nn.GRU(
            input_size=in_dim + 2,
            hidden_size=hid,
            batch_first=True
        )
        self.reset_parameters()

    def reset_parameters(self):
        for p in self.parameters():
            if p.dim() > 1:
                nn.init.xavier_uniform_(p)

    def forward(self, vel: torch.Tensor, move_flag: torch.Tensor) -> torch.Tensor:
        """
        Args:
            vel: [B, T, D] - ì†ë„ ì„ë² ë”©
            move_flag: [B, T] - ì´ë™ í”Œë˜ê·¸
        
        Returns:
            [B, T, hid] - ì´ë™ ë©”ëª¨ë¦¬ hidden states
        """
        B, T, D = vel.shape
        
        # ëˆ„ì  ì¹´ìš´í„°
        move_cnt = torch.cumsum(move_flag, dim=1).unsqueeze(-1)       # [B, T, 1]
        stay_cnt = torch.cumsum(1 - move_flag, dim=1).unsqueeze(-1)   # [B, T, 1]
        
        # ì…ë ¥ êµ¬ì„±
        x = torch.cat([vel, move_cnt, stay_cnt], dim=-1)  # [B, T, D+2]
        
        # GRU forward
        h, _ = self.gru(x)  # [B, T, hid]
        return h


class CMU(nn.Module):
    """
    Context Memory Unit (ë§¥ë½ ë©”ëª¨ë¦¬)
    
    ë§¥ë½/ì˜ì—­ ì •ë³´ë¥¼ ëˆ„ì  í•™ìŠµ:
    - ì„¼ì„œ ì„ë² ë”© (ì–´ë–¤ ì„¼ì„œê°€ í™œì„±í™”ë˜ì—ˆëŠ”ì§€)
    - EMA í‰í™œí™”ëœ ì„¼ì„œ ìƒíƒœ
    - ì •ì§€/ë¨¸ë¬´ë¦„ íŒ¨í„´
    
    ë…¸ë²¨í‹°: Context-specific memory (ì„ í–‰ ì—°êµ¬ ê±°ì˜ ì—†ìŒ) ğŸ†•
    """
    
    def __init__(self, in_dim: int, hid: int = 128):
        """
        Args:
            in_dim: ë§¥ë½ íŠ¹ì§• ì°¨ì› (base_feat + vel)
            hid: GRU hidden ì°¨ì›
        """
        super().__init__()
        # ì…ë ¥: ctx_feat + move_cnt + stay_cnt
        self.gru = nn.GRU(
            input_size=in_dim + 2,
            hidden_size=hid,
            batch_first=True
        )

    def forward(self, ctx_feat: torch.Tensor, move_flag: torch.Tensor) -> torch.Tensor:
        """
        Args:
            ctx_feat: [B, T, Dc] - ë§¥ë½ íŠ¹ì§• (base features + ê¸°íƒ€)
            move_flag: [B, T] - ì´ë™ í”Œë˜ê·¸
        
        Returns:
            [B, T, hid] - ë§¥ë½ ë©”ëª¨ë¦¬ hidden states
        """
        # ëˆ„ì  ì¹´ìš´í„°
        move_cnt = torch.cumsum(move_flag, dim=1).unsqueeze(-1)
        stay_cnt = torch.cumsum(1 - move_flag, dim=1).unsqueeze(-1)
        
        # ì…ë ¥ êµ¬ì„±
        x = torch.cat([ctx_feat, move_cnt, stay_cnt], dim=-1)  # [B, T, Dc+2]
        
        # GRU forward
        h, _ = self.gru(x)  # [B, T, hid]
        return h


class GateAndTrigger(nn.Module):
    """
    ê²Œì´íŠ¸ + íŠ¸ë¦¬ê±° ë©”ì»¤ë‹ˆì¦˜
    
    ê²Œì´íŠ¸ g_të¡œ MMU/CMU ì¶œë ¥ì„ ë™ì ìœ¼ë¡œ ìœµí•©:
    - ì´ë™ ì¤‘ì´ë©´ MMU ê°€ì¤‘ì¹˜ â†‘
    - ì •ì§€ ì¤‘ì´ë©´ CMU ê°€ì¤‘ì¹˜ â†‘
    
    íŠ¸ë¦¬ê±° ìŠ¤ì½”ì–´: í™œë™ ì „í™˜ ì‹œì  ê°ì§€ (ì˜µì…˜)
    
    ë…¸ë²¨í‹°: Movement-triggered gating (ì„ í–‰ ì—°êµ¬ ì—†ìŒ) ğŸ†•
    """
    
    def __init__(self, h_move: int, h_ctx: int):
        """
        Args:
            h_move: MMU hidden ì°¨ì›
            h_ctx: CMU hidden ì°¨ì›
        """
        super().__init__()
        
        # ê²Œì´íŠ¸: [h_move, h_ctx, move_flag] â†’ g_t âˆˆ [0, 1]
        self.gate = nn.Sequential(
            nn.Linear(h_move + h_ctx + 1, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )
        
        # íŠ¸ë¦¬ê±° ìŠ¤ì½”ì–´ (í™œë™ ì „í™˜ ê°ì§€)
        self.trig = nn.Sequential(
            nn.Linear(h_move + h_ctx, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )

    def forward(
        self,
        h_move: torch.Tensor,
        h_ctx: torch.Tensor,
        move_flag: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Args:
            h_move: [B, T, H_m] - MMU ì¶œë ¥
            h_ctx: [B, T, H_c] - CMU ì¶œë ¥
            move_flag: [B, T] - ì´ë™ í”Œë˜ê·¸
        
        Returns:
            fused: [B, T, H] - ìœµí•©ëœ hidden states
            gate: [B, T] - ê²Œì´íŠ¸ ê°€ì¤‘ì¹˜
            trigger: [B, T] - íŠ¸ë¦¬ê±° ìŠ¤ì½”ì–´
        """
        # ê²Œì´íŠ¸ ê³„ì‚°
        x = torch.cat([h_move, h_ctx], dim=-1)  # [B, T, H_m + H_c]
        g = torch.sigmoid(
            self.gate(torch.cat([x, move_flag.unsqueeze(-1)], dim=-1))
        )  # [B, T, 1]
        
        # ìœµí•©
        z = g * h_move + (1 - g) * h_ctx  # [B, T, H]
        
        # íŠ¸ë¦¬ê±° ìŠ¤ì½”ì–´
        trig_score = self.trig(x).squeeze(-1)  # [B, T]
        
        return z, g.squeeze(-1), trig_score


class TemporalEncoder(nn.Module):
    """
    ìµœì¢… temporal encoding:
    1. Projection
    2. TCN (dilated causal convolutions)
    3. BiGRU (ì–‘ë°©í–¥ temporal dependencies)
    4. Additive Attention (context aggregation)
    """
    
    def __init__(self, in_dim: int, hid: int = 128):
        """
        Args:
            in_dim: ì…ë ¥ ì°¨ì› (base + vel + fused)
            hid: hidden ì°¨ì›
        """
        super().__init__()
        
        # Projection
        self.proj = nn.Linear(in_dim, hid)
        
        # TCN with multiple dilations
        self.tcn = nn.Sequential(
            TCNBlock(hid, hid, k=3, dil=1, pdrop=0.1),
            TCNBlock(hid, hid, k=3, dil=2, pdrop=0.1),
            TCNBlock(hid, hid, k=3, dil=4, pdrop=0.1),
        )
        
        # BiGRU
        self.gru = nn.GRU(
            hid, hid, num_layers=1,
            batch_first=True, bidirectional=True
        )
        
        # Attention
        self.attn = AdditiveAttention(hid * 2)

    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            x: [B, T, F] - ì…ë ¥ íŠ¹ì§•
        
        Returns:
            ctx: [B, 2*hid] - context vector
            w: [B, T] - attention weights
        """
        h = self.proj(x)            # [B, T, hid]
        h = h.transpose(1, 2)       # [B, hid, T]
        h = self.tcn(h)             # [B, hid, T]
        h = h.transpose(1, 2)       # [B, T, hid]
        h, _ = self.gru(h)          # [B, T, 2*hid]
        ctx, w = self.attn(h)       # [B, 2*hid], [B, T]
        return ctx, w


# ==================== Top-level Model ====================

class SmartHomeModel(nn.Module):
    """
    Position-Velocity-MMU/CMU í†µí•© ëª¨ë¸
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. PositionHead: ì„¼ì„œ ID â†’ 2D ìœ„ì¹˜
    2. VelocityHead: ìœ„ì¹˜ ì°¨ë¶„ â†’ ì†ë„/ë°©í–¥ íŠ¹ì§•
    3. MMU/CMU: ì´ë™/ë§¥ë½ ë©”ëª¨ë¦¬
    4. GateAndTrigger: ë™ì  ìœµí•©
    5. TemporalEncoder: TCN â†’ BiGRU â†’ Attention
    6. Classifier: ìµœì¢… í™œë™ ë¶„ë¥˜
    
    ë…¸ë²¨í‹°:
    - í•™ìŠµ ê°€ëŠ¥í•œ ì„¼ì„œ ìœ„ì¹˜ ğŸ†•
    - MMU/CMU ì´ì¤‘ ë©”ëª¨ë¦¬ ğŸ†•
    - Movement-triggered gating ğŸ†•
    """
    
    def __init__(
        self,
        num_sensors: int,
        base_feat_dim: int,    # rich features ì°¨ì› (F_base)
        sensor_emb_dim: int = 32,
        vel_dim: int = 32,
        enc_hid: int = 128,
        mmu_hid: int = 128,
        cmu_hid: int = 128,
        n_classes: int = 5
    ):
        """
        Args:
            num_sensors: ì„¼ì„œ ê°œìˆ˜
            base_feat_dim: ê¸°ë³¸ íŠ¹ì§• ì°¨ì› (X_frame + X_ema + X_vel + X_emb)
            sensor_emb_dim: ì„¼ì„œ ì„ë² ë”© ì°¨ì›
            vel_dim: ì†ë„ ì„ë² ë”© ì°¨ì›
            enc_hid: ì¸ì½”ë” hidden ì°¨ì›
            mmu_hid: MMU hidden ì°¨ì›
            cmu_hid: CMU hidden ì°¨ì›
            n_classes: í™œë™ í´ë˜ìŠ¤ ê°œìˆ˜
        """
        super().__init__()
        
        self.num_sensors = num_sensors
        self.base_feat_dim = base_feat_dim
        self.vel_dim = vel_dim
        
        # A) ìœ„ì¹˜/ì†ë„ ê³„ì¸µ
        self.pos_head = PositionHead(num_sensors, init_scale=0.1)  # restore init scale
        self.vel_head = VelocityHead(d_model=vel_dim)
        
        # B) ë©”ëª¨ë¦¬ ê³„ì¸µ
        # CMU ì…ë ¥: base_feat + vel
        self.cmu_in_dim = base_feat_dim + vel_dim
        self.mmu = MMU(in_dim=vel_dim, hid=mmu_hid)
        self.cmu = CMU(in_dim=self.cmu_in_dim, hid=cmu_hid)
        
        # C) ê²Œì´íŠ¸/íŠ¸ë¦¬ê±°
        self.gate = GateAndTrigger(h_move=mmu_hid, h_ctx=cmu_hid)
        
        # D) ìµœì¢… ì¸ì½”ë” + ë¶„ë¥˜ê¸°
        # ìµœì¢… ì…ë ¥: base_feat + vel + fused_z
        self.encoder_in = base_feat_dim + vel_dim + max(mmu_hid, cmu_hid)
        self.encoder = TemporalEncoder(in_dim=self.encoder_in, hid=enc_hid)
        
        self.classifier = nn.Sequential(
            nn.Linear(enc_hid * 2, enc_hid),
            nn.ReLU(),
            nn.Dropout(0.5),  # Increased dropout to prevent overfitting
            nn.Linear(enc_hid, n_classes),
        )
    
    def forward(
        self,
        X_base: torch.Tensor,
        sensor_ids: torch.Tensor,
        timestamps: Optional[torch.Tensor] = None,
        return_aux: bool = False
    ):
        """
        Args:
            X_base: [B, T, F_base] - ê¸°ë³¸ íŠ¹ì§• (frames/ema/vel/emb)
            sensor_ids: [B, T] - ê° ì‹œì ì˜ ëŒ€í‘œ ì„¼ì„œ ID
            timestamps: [B, T] - íƒ€ì„ìŠ¤íƒ¬í”„ (ì˜µì…˜)
            return_aux: ì¤‘ê°„ ê²°ê³¼ ë°˜í™˜ ì—¬ë¶€
        
        Returns:
            logits: [B, n_classes]
            aux: dict (return_aux=Trueì¼ ë•Œ)
        """
        # 1) ìœ„ì¹˜/ì†ë„
        pos = self.pos_head(sensor_ids)  # [B, T, 2]
        vel, move_flag, aux_vel = self.vel_head(pos, timestamps)  # [B, T, Dv]
        
        # 2) ë©”ëª¨ë¦¬
        h_move = self.mmu(vel, move_flag)                         # [B, T, H_m]
        
        # CMU ì…ë ¥: ë§¥ë½ íŠ¹ì§• (base + vel)
        ctx_feat = torch.cat([X_base, vel], dim=-1)               # [B, T, F_base+Dv]
        h_ctx = self.cmu(ctx_feat, move_flag)                     # [B, T, H_c]
        
        # 3) ê²Œì´íŠ¸/íŠ¸ë¦¬ê±°
        fused, gate_w, trig = self.gate(h_move, h_ctx, move_flag) # [B, T, H]
        
        # 4) ìµœì¢… ì¸ì½”ë” ì…ë ¥ êµ¬ì„±
        H = torch.cat([X_base, vel, fused], dim=-1)               # [B, T, F_total]
        ctx, attn_w = self.encoder(H)                             # [B, 2*enc_hid], [B, T]
        
        # 5) ë¶„ë¥˜
        logits = self.classifier(ctx)                             # [B, n_classes]
        
        if not return_aux:
            return logits
        
        aux = {
            'pos': pos,
            'vel': vel,
            'gate': gate_w,
            'trigger': trig,
            'attn': attn_w,
            **aux_vel
        }
        return logits, aux
        
        if not return_aux:
            return logits
        
        # Auxiliary outputs (aux_vel already contains move_flag, dP, dt, speed, direction, mov_logits)
        aux = {
            'pos': pos,
            'vel': vel,
            'gate': gate_w,
            'trigger': trig,
            'attn': attn_w,
            **aux_vel  # This includes: move_flag, dP, dt, speed, direction, mov_logits
        }
        return logits, aux


# ==================== Multi-task Loss ====================

class MultiTaskLoss(nn.Module):
    """
    ë‹¤ì¤‘ ê³¼ì œ ì†ì‹¤ í•¨ìˆ˜:
    1. L_cls: í™œë™ ë¶„ë¥˜ ì†ì‹¤ (CrossEntropy)
    2. L_move: ì´ë™ ë³´ì¡° ì†ì‹¤ (ì´ë™/ì •ì§€ ì˜ˆì¸¡)
    3. L_pos: ìœ„ì¹˜ ì •ê·œí™” (ë„ˆë¬´ í° ì¢Œí‘œ ë°©ì§€)
    4. L_smooth: ì†ë„ í‰í™œí™” (ê¸‰ê²©í•œ ë³€í™” ë°©ì§€)
    """
    
    def __init__(
        self,
        lambda_move: float = 1.0,
        lambda_pos: float = 0.1,
        lambda_smooth: float = 0.01
    ):
        """
        Args:
            lambda_move: ì´ë™ ë³´ì¡° ì†ì‹¤ ê°€ì¤‘ì¹˜
            lambda_pos: ìœ„ì¹˜ ì •ê·œí™” ê°€ì¤‘ì¹˜
            lambda_smooth: ì†ë„ í‰í™œí™” ê°€ì¤‘ì¹˜
        """
        super().__init__()
        self.ce = nn.CrossEntropyLoss()
        self.bce = nn.BCEWithLogitsLoss()
        self.lambda_move = lambda_move
        self.lambda_pos = lambda_pos
        self.lambda_smooth = lambda_smooth
    
    def forward(
        self,
        logits: torch.Tensor,
        y: torch.Tensor,
        aux: Dict[str, torch.Tensor],
        learnable_positions: torch.Tensor
    ):
        """
        Args:
            logits: [B, C] - ë¶„ë¥˜ logits
            y: [B] - ì •ë‹µ ë ˆì´ë¸”
            aux: dict - ë³´ì¡° ì¶œë ¥ë“¤
            learnable_positions: [N, 2] - í•™ìŠµ ê°€ëŠ¥í•œ ì„¼ì„œ ìœ„ì¹˜
        
        Returns:
            total_loss: scalar
            losses: dict - ê° ì†ì‹¤ í•­ëª©
        """
        # 1) ë¶„ë¥˜ ì†ì‹¤
        L_cls = self.ce(logits, y)
        
        # 2) ì´ë™ ë³´ì¡° ì†ì‹¤
        mov_logits = aux['mov_logits']  # [B, T, 2]
        move_flag = aux['move_flag']    # [B, T]
        # Target: [1-move_flag, move_flag] - ensure float type
        mov_targets = torch.stack([1 - move_flag, move_flag], dim=-1).float()  # [B, T, 2]
        L_move = self.bce(mov_logits, mov_targets)
        
        # 3) ìœ„ì¹˜ ì •ê·œí™” (L2)
        L_pos = (learnable_positions ** 2).mean()
        
        # 4) ì†ë„ í‰í™œí™” (temporal smoothness)
        # Only use dP for smoothness - dt varies too much and causes instability
        dP = aux['dP']  # [B, T, 2]
        diff = dP[:, 1:] - dP[:, :-1]  # [B, T-1, 2]
        L_smooth = (diff ** 2).mean()
        
        # ì´ ì†ì‹¤
        total = (
            L_cls +
            self.lambda_move * L_move +
            self.lambda_pos * L_pos +
            self.lambda_smooth * L_smooth
        )
        
        # ê°œë³„ ì†ì‹¤ ê¸°ë¡
        losses = dict(
            L_cls=L_cls.item(),
            L_move=L_move.item(),
            L_pos=L_pos.item(),
            L_smooth=L_smooth.item()
        )
        
        return total, losses


# ==================== Test Code ====================

if __name__ == "__main__":
    """ê°„ë‹¨í•œ ë™ì‘ í…ŒìŠ¤íŠ¸"""
    torch.manual_seed(0)
    
    # Dummy data
    B, T = 4, 100
    num_sensors = 30
    F_base = 98  # 30 + 30 + 6 + 32 (frame + ema + vel + emb)
    n_classes = 5
    
    X_base = torch.randn(B, T, F_base)
    ids = torch.randint(0, num_sensors, (B, T))
    ts = torch.cumsum(torch.rand(B, T), dim=1)  # cumulative timestamps
    
    # Model
    model = SmartHomeModel(
        num_sensors=num_sensors,
        base_feat_dim=F_base,
        sensor_emb_dim=32,
        vel_dim=32,
        enc_hid=128,
        mmu_hid=128,
        cmu_hid=128,
        n_classes=n_classes
    )
    
    # Forward
    logits, aux = model(X_base, ids, ts, return_aux=True)
    print(f"âœ“ logits shape: {logits.shape}")  # [B, C]
    print(f"âœ“ pos shape: {aux['pos'].shape}")  # [B, T, 2]
    print(f"âœ“ vel shape: {aux['vel'].shape}")  # [B, T, 32]
    print(f"âœ“ move_flag shape: {aux['move_flag'].shape}")  # [B, T]
    print(f"âœ“ gate shape: {aux['gate'].shape}")  # [B, T]
    
    # Loss
    loss_fn = MultiTaskLoss(lambda_move=1.0, lambda_pos=0.1, lambda_smooth=0.01)
    y = torch.randint(0, n_classes, (B,))
    total, ld = loss_fn(logits, y, aux, model.pos_head.positions)
    print(f"\nâœ“ total_loss: {total.item():.4f}")
    print(f"âœ“ loss_dict: {ld}")
    
    # Parameter count
    n_params = sum(p.numel() for p in model.parameters())
    print(f"\nâœ“ Total parameters: {n_params:,}")
